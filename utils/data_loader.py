"""
data_loader.py: Carga y cach√© de datos

Funciones para cargar el CSV principal con optimizaci√≥n de memoria
mediante cach√© de Streamlit (@st.cache_data).
"""

import pandas as pd
import streamlit as st
from pathlib import Path


@st.cache_data  # Cach√© autom√°tico - los datos se cargan 1 sola vez
def cargar_datos(ruta: str = "static/datasets/suicidios_antioquia.csv") -> pd.DataFrame:
    """
    Carga el dataset principal con validaciones y optimizaciones.
    
    Args:
        ruta (str): Ruta relativa al archivo CSV
        
    Returns:
        pd.DataFrame: Dataset limpio y validado
        
    Raises:
        FileNotFoundError: Si el archivo no existe
        ValueError: Si el dataset est√° vac√≠o o tiene columnas faltantes
        
    Ejemplo de uso:
        df = cargar_datos()
        print(f"Cargados {len(df)} registros")
    """
    #  Verificar que el archivo existe
    archivo = Path(ruta)
    if not archivo.exists():
        raise FileNotFoundError(
            f"‚ùå No se encontr√≥ el archivo: {ruta}\n"
            f"Verifica que la estructura de carpetas sea correcta."
        )
    
    #  Cargar CSV con optimizaciones
    try:
        df = pd.read_csv(
            ruta,
            encoding='utf-8',  # Asegurar compatibilidad con tildes
            dtype={
                'CodigoMunicipio': 'int32',    # Optimizaci√≥n de memoria
                'CodigoRegion': 'int8',        # Regiones: 1-9
                'Anio': 'int16',               # A√±os: 2005-2024
                'NumeroCasos': 'int16'         # Casos: 0-246
            }
        )
        
        #  Convertir columnas categ√≥ricas (ahorra memoria)
        df['NombreRegion'] = df['NombreRegion'].astype('category')
        df['NombreMunicipio'] = df['NombreMunicipio'].astype('category')
        df['CausaMortalidad'] = df['CausaMortalidad'].astype('category')
        df['TipoPoblacionObjetivo'] = df['TipoPoblacionObjetivo'].astype('category')
        
        #  Limpiar columna de poblaci√≥n (eliminar comas y convertir a int)
        if df['NumeroPoblacionObjetivo'].dtype == 'object':
            df['NumeroPoblacionObjetivo'] = (
                df['NumeroPoblacionObjetivo']
                .str.replace(',', '', regex=False)
                .astype('int32')
            )
        
        #  Validaciones de integridad
        
        # Validaci√≥n 1: Dataset no vac√≠o
        if df.empty:
            raise ValueError("‚ùå El dataset est√° vac√≠o")
        
        # Validaci√≥n 2: Columnas requeridas
        columnas_requeridas = [
            'NombreMunicipio', 'CodigoMunicipio', 'NombreRegion',
            'Anio', 'NumeroCasos', 'NumeroPoblacionObjetivo'
        ]
        columnas_faltantes = set(columnas_requeridas) - set(df.columns)
        if columnas_faltantes:
            raise ValueError(f"‚ùå Columnas faltantes: {columnas_faltantes}")
        
        # Validaci√≥n 3: Rango de a√±os
        if (df['Anio'] < 2005).any() or (df['Anio'] > 2024).any():
            st.warning("‚ö†Ô∏è Advertencia: Se encontraron a√±os fuera del rango esperado (2005-2024)")
        
        # Validaci√≥n 4: Casos negativos
        if (df['NumeroCasos'] < 0).any():
            raise ValueError("‚ùå Error cr√≠tico: Existen casos negativos en los datos")
        
        # Validaci√≥n 5: Poblaci√≥n cero o negativa
        if (df['NumeroPoblacionObjetivo'] <= 0).any():
            registros_invalidos = df[df['NumeroPoblacionObjetivo'] <= 0].shape[0]
            st.warning(
                f"‚ö†Ô∏è Advertencia: {registros_invalidos} registros tienen poblaci√≥n ‚â§ 0. "
                f"Esto puede afectar el c√°lculo de tasas."
            )
        
        # Validaci√≥n 6: Valores nulos cr√≠ticos
        nulos_casos = df['NumeroCasos'].isna().sum()
        nulos_poblacion = df['NumeroPoblacionObjetivo'].isna().sum()
        
        if nulos_casos > 0 or nulos_poblacion > 0:
            st.warning(
                f"‚ö†Ô∏è Valores nulos encontrados: "
                f"Casos={nulos_casos}, Poblaci√≥n={nulos_poblacion}"
            )
        
        return df
        
    except pd.errors.EmptyDataError:
        raise ValueError("‚ùå El archivo CSV est√° vac√≠o o corrupto")
    except pd.errors.ParserError as e:
        raise ValueError(f"‚ùå Error al parsear CSV: {str(e)}")
    except Exception as e:
        raise Exception(f"‚ùå Error inesperado al cargar datos: {str(e)}")

@st.cache_data
def obtener_metadatos(df: pd.DataFrame) -> dict:
    """
    Extrae metadatos estad√≠sticos del dataset para mostrar en p√°ginas.
    
    Args:
        df (pd.DataFrame): Dataset cargado
        
    Returns:
        dict: Diccionario con estad√≠sticas principales:
            - total_registros: N√∫mero total de filas
            - total_municipios: Municipios √∫nicos
            - total_regiones: Regiones √∫nicas
            - anio_inicio: A√±o m√≠nimo
            - anio_fin: A√±o m√°ximo
            - total_casos: Suma de casos hist√≥ricos
            - poblacion_total: Suma de poblaci√≥n
            - casos_promedio_anual: Promedio de casos por a√±o
            - memoria_mb: Memoria usada por el DataFrame
            
    Ejemplo de uso:
        meta = obtener_metadatos(df)
        print(f"Total de casos: {meta['total_casos']:,}")
    """
    return {
        'total_registros': len(df),
        'total_municipios': df['NombreMunicipio'].nunique(),
        'total_regiones': df['NombreRegion'].nunique(),
        'anio_inicio': int(df['Anio'].min()),
        'anio_fin': int(df['Anio'].max()),
        'total_casos': int(df['NumeroCasos'].sum()),
        'poblacion_total': int(df['NumeroPoblacionObjetivo'].sum()),
        'casos_promedio_anual': round(df.groupby('Anio')['NumeroCasos'].sum().mean(), 1),
        'memoria_mb': round(df.memory_usage(deep=True).sum() / 1024**2, 2)
    }


def verificar_duplicados(df: pd.DataFrame) -> pd.DataFrame:
    """
    Identifica registros duplicados por municipio-a√±o.
    
    En un dataset bien estructurado, NO deber√≠a haber duplicados
    (cada combinaci√≥n municipio-a√±o debe ser √∫nica).
    
    Args:
        df (pd.DataFrame): Dataset a verificar
        
    Returns:
        pd.DataFrame: DataFrame con registros duplicados (vac√≠o si no hay).
                     Ordenado por CodigoMunicipio y Anio.
                     
    Efectos secundarios:
        Muestra advertencia en Streamlit si encuentra duplicados.
        
    Ejemplo de uso:
        duplicados = verificar_duplicados(df)
        if not duplicados.empty:
            st.dataframe(duplicados)
    """
    # Identificar duplicados (keep=False marca TODOS los duplicados, no solo el segundo)
    duplicados = df[df.duplicated(subset=['CodigoMunicipio', 'Anio'], keep=False)]
    
    if not duplicados.empty:
        num_grupos = duplicados.groupby(['CodigoMunicipio', 'Anio']).ngroups
        st.warning(
            f"‚ö†Ô∏è Se encontraron {len(duplicados)} registros duplicados "
            f"correspondientes a {num_grupos} combinaciones municipio-a√±o √∫nicas.\n\n"
            f"**Recomendaci√≥n:** Revisar y consolidar estos registros antes del an√°lisis."
        )
    
    return duplicados.sort_values(['CodigoMunicipio', 'Anio'])


def limpiar_cache():
    """
    Limpia el cach√© de Streamlit para forzar recarga de datos.
    
    ‚ö†Ô∏è ADVERTENCIA: Usar solo en desarrollo. Borrar√° todos los datos cacheados
    y la pr√≥xima ejecuci√≥n ser√° m√°s lenta.
    
    Ejemplo de uso:
        if st.button("üîÑ Recargar datos"):
            limpiar_cache()
            st.rerun()
    """
    st.cache_data.clear()
    st.success("‚úÖ Cach√© limpiado. Los datos se recargar√°n en la pr√≥xima ejecuci√≥n.")


#  Funci√≥n auxiliar: Res√∫men r√°pido
def resumen_dataset(df: pd.DataFrame) -> None:
    """
    Muestra un resumen visual r√°pido del dataset en Streamlit.
    √ötil para debugging o p√°ginas de diagn√≥stico.
    
    Args:
        df (pd.DataFrame): Dataset a resumir
        
    Ejemplo de uso:
        df = cargar_datos()
        resumen_dataset(df)
    """
    meta = obtener_metadatos(df)
    
    st.markdown("### üìä Resumen del Dataset")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Registros", f"{meta['total_registros']:,}")
    
    with col2:
        st.metric("Municipios", f"{meta['total_municipios']}")
    
    with col3:
        st.metric("Casos Totales", f"{meta['total_casos']:,}")
    
    with col4:
        st.metric("Memoria", f"{meta['memoria_mb']:.2f} MB")
    
    st.markdown(f"""
    - **Per√≠odo:** {meta['anio_inicio']} - {meta['anio_fin']} ({meta['anio_fin'] - meta['anio_inicio'] + 1} a√±os)
    - **Regiones:** {meta['total_regiones']}
    - **Promedio anual:** {meta['casos_promedio_anual']:.1f} casos/a√±o
    """)
